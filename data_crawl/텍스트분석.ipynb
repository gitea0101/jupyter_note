{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 정제\n",
    "- 형태소 분석 (split)\n",
    "    - 태그만 추출, 사용\n",
    "- .morphs() : 형태소 단위로 분리\n",
    "- .nouns() : 명사만 추출\n",
    "- .pos() : 품사 태깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### okt 만 제공하는 함수\n",
    "- 문장 정규화 okt.morphs(text, norm=True)\n",
    "- 어간 추출 okt.morphs(text, stem=True)\n",
    "- 동시사용 okt.morphs(text, norm=True,stem=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['설치', '가', '잘', '되었는지', '확인', '해봅시다', '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "\n",
    "okt.morphs('설치가 잘 되었는지 확인 해봅시다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '오늘', '친구', '와', '함께', '영화', '를', '볼', '계획', '이다', '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '나는 오늘 친구와 함께 영화를 볼 계획이다.'\n",
    "\n",
    "okt.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나', 'Noun'),\n",
       " ('는', 'Josa'),\n",
       " ('오늘', 'Noun'),\n",
       " ('친구', 'Noun'),\n",
       " ('와', 'Josa'),\n",
       " ('함께', 'Adverb'),\n",
       " ('영화', 'Noun'),\n",
       " ('를', 'Josa'),\n",
       " ('볼', 'Noun'),\n",
       " ('계획', 'Noun'),\n",
       " ('이다', 'Josa'),\n",
       " ('.', 'Punctuation')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '오늘', '친구', '영화', '볼', '계획']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '오늘', '끝나다', '저녁', '맛있다', '먹다', '얔', 'ㅋㅋㅋ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='나는 오늘 끝나고 저녁 맛있는거 먹을꺼얔ㅋㅋㅋ'\n",
    "\n",
    "okt.morphs(text, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '오늘', '끝나고', '저녁', '맛있는거', '먹을꺼야', 'ㅋㅋㅋ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(text, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '오늘', '끝나다', '저녁', '맛있다', '먹다', 'ㅋㅋㅋ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(text, norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나', 'Noun'),\n",
       " ('는', 'Josa'),\n",
       " ('오늘', 'Noun'),\n",
       " ('끝나다', 'Verb'),\n",
       " ('저녁', 'Noun'),\n",
       " ('맛있다', 'Adjective'),\n",
       " ('먹다', 'Verb'),\n",
       " ('ㅋㅋㅋ', 'KoreanParticle')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(text, norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거하기\n",
    "- 자주 사용되지만 특별한 의미 부여가 어려운 단어들을 제거\n",
    "- 일반적으로 불용어 사전은 리스트 형태를 만들어 사용\n",
    "- 불용어 사전이 있다고 가정했을 때 불용어를 제거하는 define 함수를 만들어보자\n",
    "- 불용어가 제거되고, 형용사와 동사만 추출할 수 있는 define 함수를 만들어 보자\n",
    "- 태그이름 형용사 : 'Adjective', 동사 : 'Verb', 명사 : 'Noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화면', '고양이', '출근']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['있다', '되다', '하다']\n",
    "# text='나는 오늘 끝나고 저녁 맛있는거 먹을꺼얔ㅋㅋㅋ'\n",
    "\n",
    "text = '화면이 있다. 고양이가 출근 하다'\n",
    "def extract_tags(value):\n",
    "    v_pos = okt.pos(value, stem=True, norm = True)\n",
    "    \n",
    "    n=0\n",
    "    n_list =[]\n",
    "    while n < len(v_pos):\n",
    "        for j in stopwords:\n",
    "            if v_pos[n][0] == j:\n",
    "                n_list.append(n)\n",
    "        n = n+1\n",
    "    n_list.sort(reverse = True)\n",
    "    for i in n_list:\n",
    "        del v_pos[i]\n",
    "        \n",
    "    result =[]\n",
    "    for i in v_pos:\n",
    "        if i[1] == 'Adjective' or i[1] == 'Verb' or i[1] == 'Noun':\n",
    "            result.append(i[0])\n",
    "    return result\n",
    "extract_tags(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화면', '고양이', '출근']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_tag(string):\n",
    "    result_word=[]\n",
    "    result = okt.pos(string, stem = True, norm = True)\n",
    "    for word, tag in result:\n",
    "        if tag in['Verb', 'Noun', 'Adjective']:\n",
    "            if word not in stopwords:\n",
    "                result_word.append(word)\n",
    "    return result_word\n",
    "\n",
    "extract_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'Persian', 'cat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The little yellow dog barked at the Persian cat'\n",
    "\n",
    "split_text = nltk.word_tokenize(text)\n",
    "\n",
    "split_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('yellow', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Persian', 'JJ'),\n",
       " ('cat', 'NN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the little yellow dog barked at the persian cat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('english') #소문자만 있음\n",
    "\n",
    "text.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거\n",
    "- 동사, 형용사, 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Love']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I Love You'\n",
    "\n",
    "def extract_tag_english(string):\n",
    "    \n",
    "    split_string = nltk.word_tokenize(string)\n",
    "    result = nltk.pos_tag(split_string)\n",
    "    \n",
    "    result_word=[]\n",
    "    for word, tag in result:\n",
    "        # if word.lower() in nltk.corpus.stopwords.words('english'):\n",
    "        #     continue\n",
    "        if tag in['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ' 'JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            if word.lower() not in nltk.corpus.stopwords.words('english'):\n",
    "                result_word.append(word)\n",
    "    return result_word\n",
    "\n",
    "extract_tag_english(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle 라이브러리\n",
    "- 데이터프레임의 형태로 저장하기 곤란할 때\n",
    "- 데이터를 타입 그대로 저장해주는 파이썬 내장 라이브러리\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 저장하기\n",
    "# with open('파일 이름.pkl', \"wb\") as f:\n",
    "#     pickle.dump(저장할 변수, f)\n",
    "    \n",
    "# 불러오기\n",
    "# with open('파일 이름.pkl', \"rb\") as f:\n",
    "#     피클 데이터의 변수이름 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The little yellow dog barked at the Persian cat'\n",
    "result = nltk.word_tokenize(text)\n",
    "\n",
    "with open('save_data.pkl', 'wb') as f:\n",
    "    pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'Persian', 'cat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('save_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
